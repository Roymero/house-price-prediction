{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Graphing libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing all soup to nuts libraries\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Importing regression boosting\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "train_dataframe = pd.read_csv('data/train.csv')\n",
    "test_dataframe = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Describing train data\n",
    "train_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out dataframe columns\n",
    "\n",
    "train_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for all possible numerical columns that we can utilize\n",
    "# Now we'll start preprocesssing data\n",
    "\n",
    "train_dataframe.dtypes[train_dataframe.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we're going to compare different attributes to sales price to see the positive/negative correlation \n",
    "# Starting with lot frontage \n",
    "# Below is a graph comparing Lot Frontage to Sales Price\n",
    "\n",
    "\n",
    "plt.scatter(x='LotFrontage', y='SalePrice', data=train_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##There are a few outliers to the right but overall we can see a positive correlation between LotFrontage and SalePrice\n",
    "# Lets grab id of the two outlier plotpoints so we can remove them to obtain more cohesive data\n",
    "\n",
    "train_dataframe.query('LotFrontage > 300')\n",
    "\n",
    "# We're going to remove 935 and 1299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing with the trend above we're going to continue comparisons to sales price and also continue removing outliers\n",
    "# Next is overall quality, we're going to compare OverallQual to SalePrice \n",
    "\n",
    "plt.scatter(x='OverallQual', y='SalePrice', data=train_dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see OverallQual has a postive correlation with SalePrice\n",
    "# There's a outlier in the end but I believe we can keep it\n",
    "# Next we will do lot area \n",
    "\n",
    "plt.scatter(x='LotArea', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are four outliers that I would like to remove\n",
    "\n",
    "train_dataframe.query('LotArea > 55000')\n",
    "# Looking to drop 250, 314, 336, 707\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next value is year built\n",
    "\n",
    "plt.scatter(x='YearBuilt', y='SalePrice', data=train_dataframe)\n",
    "\n",
    "# No outliers I want to remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall condition comparison\n",
    "\n",
    "plt.scatter(x='OverallCond', y='SalePrice', data=train_dataframe)\n",
    "\n",
    "# There is one outlier in column two I want to remove\n",
    "# 379\n",
    "train_dataframe.query(\"OverallCond==2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year Built \n",
    "\n",
    "plt.scatter(x='YearBuilt', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a single outlier house that was built before 1900 and is almost 500k\n",
    "# We will be repeating this process for every numerical attribute. Comments will be less common to better streamline the project\n",
    "train_dataframe.query('YearBuilt < 1900 & SalePrice > 400000')\n",
    "# Remove: 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year Modeling date\n",
    "\n",
    "plt.scatter(x='YearRemodAdd', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No outliers to drop above\n",
    "\n",
    "# Masonry veneer type\n",
    "plt.scatter(x='MasVnrArea', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe.query('MasVnrArea > 1350')\n",
    "\n",
    "# Removing:\n",
    "# 298\n",
    "# 1170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtFinSF1: Type 1 finished square feet\n",
    "plt.scatter(x='BsmtFinSF1', y='SalePrice', data=train_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier to the right with high amount of finished square feet and low price\n",
    "train_dataframe.query('BsmtFinSF1 > 5000')\n",
    "\n",
    "# Remove: 1299\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtFinSF1: Type 1 finished square feet\n",
    "plt.scatter(x='BsmtFinSF2', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier in between the 400 - 600 column\n",
    "train_dataframe.query('BsmtFinSF2 > 400 & SalePrice > 500000')\n",
    "\n",
    "# drop: 441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtUnfSF: Unfinished square feet of basement area\n",
    "# No outliers on this one\n",
    "plt.scatter(x='BsmtUnfSF', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalBsmtSF: Total square feet of basement area\n",
    "plt.scatter(x='TotalBsmtSF', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier\n",
    "train_dataframe.query('TotalBsmtSF > 5000')\n",
    "\n",
    "# Drop: 1299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1stFlrSF: First Floor square feet\n",
    "# No outliers\n",
    "plt.scatter(x='1stFlrSF', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ndFlrSF: Second Floor square feet\n",
    "# No outliers\n",
    "plt.scatter(x='2ndFlrSF', y='SalePrice', data=train_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LowQualFinSF: Low quality finished square feet\n",
    "plt.scatter(x='LowQualFinSF', y='SalePrice', data=train_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier to the right\n",
    "train_dataframe.query('LowQualFinSF > 500')\n",
    "\n",
    "# Drop: 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtFullBath: Basement full bathrooms\n",
    "plt.scatter(x='BsmtFullBath', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier to the right\n",
    "train_dataframe.query('BsmtFullBath == 3')\n",
    "\n",
    "# Drop: 739\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrLivArea: Above grade (ground) living area square feet\n",
    "plt.scatter(x='GrLivArea', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see two outliers to the right\n",
    "train_dataframe.query('GrLivArea > 4400')\n",
    "\n",
    "# Drop 524, 1299\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFullBath: Basement half bathrooms\n",
    "plt.scatter(x='BsmtHalfBath', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier with the 3 full baths and a low price\n",
    "train_dataframe.query('BsmtFullBath == 2')\n",
    "\n",
    "# Drop 598 and 955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FullBath: Full bathrooms above grade\n",
    "# No outliers\n",
    "plt.scatter(x='FullBath', y='SalePrice', data=train_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HalfBath: Half baths above grade\n",
    "#No outliers\n",
    "plt.scatter(x='HalfBath', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KitchenAbvGr Kitchens above grade\n",
    "plt.scatter(x='KitchenAbvGr', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two outliers with 3 kitchens and low sales price\n",
    "train_dataframe.query('KitchenAbvGr == 3')\n",
    "\n",
    "#Drop: 49 and 810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BedroomAbvGr: bedrooms above grade\n",
    "plt.scatter(x='BedroomAbvGr', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier with 8 bedrooms\n",
    "train_dataframe.query('BedroomAbvGr == 8')\n",
    "\n",
    "# Drop 636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotRmsAbvGrd: Total rooms above grade\n",
    "\n",
    "plt.scatter(x='TotRmsAbvGrd', y='SalePrice', data=train_dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An outlier to the right with 14 rooms and low price\n",
    "\n",
    "train_dataframe.query('TotRmsAbvGrd == 14')\n",
    "\n",
    "# Drop: 636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageYrBlt: Year that garage was built\n",
    "# No outliers\n",
    "plt.scatter(x='GarageYrBlt', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCars: Number of cars that Garage can hold\n",
    "# No outliers\n",
    "plt.scatter(x='GarageCars', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageArea: Area of garage \n",
    "\n",
    "plt.scatter(x='GarageArea', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two outliers with large garage area and low sales price \n",
    "train_dataframe.query('GarageArea > 1200')\n",
    "\n",
    "# Drop 1062, 1191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fireplaces: Number of fireplaces\n",
    "# No outliers\n",
    "plt.scatter(x='Fireplaces', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WoodDeckSF: Wood deck area in square feet\n",
    "plt.scatter(x='WoodDeckSF', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenPorchSF: OpenPorchSF: Open porch area in square feet\n",
    "plt.scatter(x='OpenPorchSF', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier with high OpenPorchSF and low SalePrice\n",
    "\n",
    "train_dataframe.query('OpenPorchSF > 500')\n",
    "\n",
    "# Drop: 496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclosed Porch Area\n",
    "plt.scatter(x='EnclosedPorch', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One outlier \n",
    "train_dataframe.query('EnclosedPorch > 500')\n",
    "\n",
    "# Drop: 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScreenPorch: Screen porch area in square feet\n",
    "plt.scatter(x='ScreenPorch', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3SsnPorch: Three season porch area in square feet\n",
    "plt.scatter(x='3SsnPorch', y='SalePrice', data=train_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnclosedPorch: Enclosed porch area in square feet\n",
    "plt.scatter(x='PoolArea', y='SalePrice', data=train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping outliers and creating training dataframe\n",
    "dropped_values = [935, 1299, 250, 314, 336, 707, 379, 186, 298, 1170, 441, 739, 524, 598, 955, 49, 810, 636, 1062, 1191]\n",
    "\n",
    "train_dataframe = train_dataframe[train_dataframe.Id.isin(dropped_values) == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Null Values per column and deciding which columns to drop\n",
    "pd.DataFrame(train_dataframe.isnull().sum().sort_values(ascending=False)).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Columns with heavy amounts of missing values from both training and test dataframes or attributes that are irrelevant to our model\n",
    "\n",
    "train_dataframe = train_dataframe.drop(columns=['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'GarageYrBlt', 'GarageCond', 'BsmtFinType2'])\n",
    "train_dataframe.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = test_dataframe.drop(columns=['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'GarageYrBlt', 'GarageCond', 'BsmtFinType2'])\n",
    "test_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at columns with NaN values that can be filled in or changed in order to give us data we use in our model\n",
    "# Starting with MasVnrType\n",
    "\n",
    "train_dataframe['MasVnrType'].unique() \n",
    "\n",
    "# We're going to replace the NaN type with a \"No\" value\n",
    "\n",
    "train_dataframe['MasVnrType'].fillna('No', inplace=True)\n",
    "test_dataframe['MasVnrType'].fillna('No', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot for MasVnrType to see how the attribute changed after value substitution\n",
    "sns.catplot(data=train_dataframe, x=\"MasVnrType\", y=\"SalePrice\", kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in numerical values with zero for MasVnrArea\n",
    "train_dataframe['MasVnrArea'].fillna(0, inplace=True)\n",
    "test_dataframe['MasVnrArea'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in nan values for FirePlaceQu\n",
    "train_dataframe['FireplaceQu'].unique()\n",
    "\n",
    "train_dataframe['FireplaceQu'].fillna('No', inplace=True)\n",
    "test_dataframe['FireplaceQu'].fillna('No', inplace=True)\n",
    "\n",
    "# For BsmtFinType1 we're filling in the nan values with unfinished attribute instead\n",
    "train_dataframe['BsmtFinType1'].fillna('Unf', inplace=True)\n",
    "test_dataframe['BsmtFinType1'].fillna('Unf', inplace=True)\n",
    "\n",
    "\n",
    "# Filling in values for LotFrontage\n",
    "train_dataframe['LotFrontage'].fillna(0, inplace=True)\n",
    "test_dataframe['LotFrontage'].fillna(0, inplace=True)\n",
    "\n",
    "# Filling in values for GarageType and GarageQuality \n",
    "train_dataframe['GarageType'].fillna('No', inplace=True)\n",
    "test_dataframe['GarageType'].fillna('No', inplace=True)\n",
    "\n",
    "# Changing the nan values in BsmtExposure to no\n",
    "train_dataframe['BsmtExposure'].fillna('No', inplace=True)\n",
    "test_dataframe['BsmtExposure'].fillna('No', inplace=True)\n",
    "\n",
    "# For the next attribute, BsmtQual is actually the height of the basement\n",
    "train_dataframe['BsmtQual'].fillna('No', inplace=True)\n",
    "test_dataframe['BsmtQual'].fillna('No', inplace=True)\n",
    "\n",
    "train_dataframe['BsmtCond'].fillna('No', inplace=True)\n",
    "test_dataframe['BsmtCond'].fillna('No', inplace=True)\n",
    "\n",
    "# For the electrical attribute we're going to fill the nan value with SBrk which is the standard circuit and breaker\n",
    "\n",
    "train_dataframe['Electrical'].fillna('SBrkr', inplace=True)\n",
    "test_dataframe['Electrical'].fillna('SBrkr', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next I'd like to create some features to include in our model\n",
    "\n",
    "# Total Square Feet \n",
    "train_dataframe['TotalSF'] = train_dataframe['1stFlrSF'] + train_dataframe['2ndFlrSF'] + train_dataframe['BsmtFinSF1'] + train_dataframe['BsmtFinSF2']\n",
    "test_dataframe['TotalSF'] = test_dataframe['1stFlrSF'] + test_dataframe['2ndFlrSF'] + test_dataframe['BsmtFinSF1'] + test_dataframe['BsmtFinSF2']\n",
    "\n",
    "# Total Area \n",
    "train_dataframe['TotalArea'] = train_dataframe['TotalBsmtSF'] + train_dataframe['GrLivArea'] \n",
    "test_dataframe['TotalArea'] = test_dataframe['TotalBsmtSF'] + test_dataframe['GrLivArea'] \n",
    "\n",
    "# Age of the house \n",
    "train_dataframe['HouseAge'] = train_dataframe['YrSold'] - train_dataframe['YearBuilt']\n",
    "test_dataframe['HouseAge'] = test_dataframe['YrSold'] - test_dataframe['YearBuilt']\n",
    "\n",
    "# Total number of baths\n",
    "train_dataframe['TotalBaths'] = train_dataframe['FullBath'] + train_dataframe['BsmtFullBath'] + (0.5 * (train_dataframe['HalfBath'] + train_dataframe['BsmtHalfBath']))\n",
    "test_dataframe['TotalBaths'] = test_dataframe['FullBath'] + test_dataframe['BsmtFullBath'] + (0.5 * (test_dataframe['HalfBath'] + test_dataframe['BsmtHalfBath']))\n",
    "\n",
    "# How old the remodeling is, age of remodel\n",
    "train_dataframe['HouseRemodAge'] = train_dataframe['YrSold'] - train_dataframe['YearRemodAdd']\n",
    "test_dataframe['HouseRemodAge'] = test_dataframe['YrSold'] - test_dataframe['YearRemodAdd']\n",
    "\n",
    "# Total Porch Squarefeet \n",
    "train_dataframe['TotalPorchSF'] = train_dataframe['OpenPorchSF'] + train_dataframe['WoodDeckSF']  + train_dataframe['ScreenPorch']  + train_dataframe['3SsnPorch'] + train_dataframe['EnclosedPorch']\n",
    "test_dataframe['TotalPorchSF'] = test_dataframe['OpenPorchSF'] + test_dataframe['WoodDeckSF']  + test_dataframe['ScreenPorch']  + test_dataframe['3SsnPorch'] + test_dataframe['EnclosedPorch']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the unnecessary columns and columns that were used to create our new features\n",
    "\n",
    "train_dataframe = train_dataframe.drop(columns=['Id','BsmtFinSF1', 'BsmtFinSF2', 'GrLivArea', 'TotalBsmtSF','BsmtFullBath', 'FullBath', 'BsmtHalfBath','YrSold', 'YearBuilt', 'YearRemodAdd', '1stFlrSF', '2ndFlrSF', 'OpenPorchSF', '3SsnPorch', 'EnclosedPorch', 'ScreenPorch','WoodDeckSF', 'HalfBath'])\n",
    "test_dataframe = test_dataframe.drop(columns=['BsmtFinSF1', 'BsmtFinSF2', 'GrLivArea', 'TotalBsmtSF','BsmtFullBath', 'FullBath', 'BsmtHalfBath','YrSold', 'YearBuilt', 'YearRemodAdd', '1stFlrSF', '2ndFlrSF', 'OpenPorchSF', '3SsnPorch', 'EnclosedPorch', 'ScreenPorch','WoodDeckSF', 'HalfBath'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a correlation graph between numeric attributes\n",
    "\n",
    "correlation = train_dataframe.corr(numeric_only=True) \n",
    "plt.figure(figsize=(22,14))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".3f\")\n",
    "\n",
    "# Dropping GarageArea because of the high correlation of GarageCars\n",
    "train_dataframe = train_dataframe.drop(columns=['GarageArea'])\n",
    "test_dataframe = test_dataframe.drop(columns=['GarageArea'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a histogram to show the number of houses at each pricepoint\n",
    "\n",
    "# Running a log through Saleprice to get a better blanced histogram\n",
    "train_dataframe['SalePrice'] = np.log1p(train_dataframe['SalePrice'])\n",
    "\n",
    "sns.histplot(train_dataframe, x=train_dataframe['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to take the columns that are objects and use ordinal encoding or one hot encoding to include them\n",
    "train_dataframe.dtypes[train_dataframe.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing columns between ordinal coding and OHE.\n",
    "# We're also going to prep our numerical column\n",
    "\n",
    "num_cols = train_dataframe.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Dropping SalePrice \n",
    "num_cols = num_cols.drop('SalePrice')\n",
    "\n",
    "# Rule of thumb is if order of value matters then we put the object attribute under ordinal\n",
    "\n",
    "ordinal_cols = ['GarageFinish', 'HeatingQC', 'ExterQual', 'GarageQual', 'BsmtCond', 'BsmtExposure', 'KitchenQual', 'Functional', 'ExterCond', 'PavedDrive', 'LotShape', 'LandContour', 'BsmtQual', 'BsmtFinType1','Utilities', 'CentralAir','LandSlope', 'FireplaceQu']\n",
    "\n",
    "hot_cols = ['Street','Exterior1st', 'Exterior2nd','Condition1', 'Condition2', 'HouseStyle', 'RoofStyle', 'LotConfig', 'Neighborhood','Heating', 'BldgType','GarageType', 'RoofMatl', 'Electrical','SaleType', 'MSZoning', 'SaleCondition', 'Foundation','MasVnrType']\n",
    "\n",
    "train_dataframe.dtypes[train_dataframe.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to create the three model pipelines\n",
    "# Pipelines will go as follows:\n",
    "# impute -> Ordinal Encoder\n",
    "# impute -> OneHotEncoder\n",
    "# impute -> scaler\n",
    "\n",
    "ordinal_pipeline = Pipeline(steps=[('impute', SimpleImputer(strategy='most_frequent')), ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "hot_pipeline = Pipeline(steps=[('impute', SimpleImputer(strategy='most_frequent')), ('hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "num_pipeline = Pipeline(steps=[('impute', SimpleImputer(strategy='mean')),('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Column transformer\n",
    "column_transformer = ColumnTransformer(transformers=[('ordinal_pipe', ordinal_pipeline, ordinal_cols), ('hot_pipe', hot_pipeline, hot_cols), ('num_pipe', num_pipeline, num_cols)], remainder='passthrough', n_jobs=-1)\n",
    "\n",
    "# Preprocessing our pipeline\n",
    "preprocess_pipeline = Pipeline(steps=[('preprocessing', column_transformer)])\n",
    "\n",
    "# Creating X and Y coordinates \n",
    "\n",
    "x = train_dataframe.drop('SalePrice', axis=1)\n",
    "y = train_dataframe['SalePrice']\n",
    "\n",
    "# Preprocessing x\n",
    "x_preprocess = preprocess_pipeline.fit_transform(x)\n",
    "\n",
    "#Splitting training Data\n",
    "# Used a traditional 80/20 split with a random state of 30\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_preprocess, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're going to build the model\n",
    "\n",
    "# Starting Linear Regression solution\n",
    "# Initializing Object, defining param grid and then starting crossvalidation\n",
    "# After that the training data will be fit and the code will print out best score and best params.\n",
    "# This is the flowchart that will be followed with all the Regressor and Random Forest solutions\n",
    "linear_r = LinearRegression()\n",
    "\n",
    "# Fitting Data\n",
    "linear_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating Y Prediction\n",
    "y_prediction_linear = linear_r.predict(X_test)\n",
    "\n",
    "# MSE calculation\n",
    "mean_squared_error(y_test, y_prediction_linear)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting our Random Forest Regressor solution\n",
    "RF = RandomForestRegressor(random_state=10)\n",
    "param_RF = {'max_depth' : [5, 10, 15], 'n_estimators': [100, 200, 600], 'min_samples_split': [3, 5, 10]}\n",
    "RF_cv = GridSearchCV(RF, param_RF, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "RF_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best score with Random Forest Regressor\n",
    "np.sqrt(-1 * RF_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters for Random Forest Regressor\n",
    "RF_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staring our XGB Regressor solution\n",
    "XGB = XGBRegressor(random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating GB params\n",
    "param_GB ={'max_depth': [3],'n_estimators': [300],'learning_rate': [0.05, 0.1, 0.2], 'min_child_weight': [1,2,3], 'gamma': [0, 0.1, 0.2], 'subsample': [0.8, 0.9, 1.0], 'colsample_bytree': [0.8, 0.9, 1.0],}\n",
    "\n",
    "# Running GB CV\n",
    "GB_cv = GridSearchCV(XGB, param_GB, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "GB_cv.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out best GB score\n",
    "np.sqrt(-1 * GB_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out best params for GB\n",
    "GB_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Gradient Boosting Regressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "param_GBR = {'max_depth' : [15, 20, 25], 'n_estimators': [100, 500, 1200], 'min_samples_leaf': [10, 30, 50],'max_features': [0.01, 0.1, 0.7] ,'learning_rate': [0.001, 0.01, 0.1]}\n",
    "\n",
    "GBR_cv = GridSearchCV(GBR, param_GBR, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "GBR_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out best GBR Score \n",
    "np.sqrt(-1 * GBR_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out best GBR Parameters \n",
    "GBR_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM Regressor solution\n",
    "#(scrapped)\n",
    "#LGBM = lgb.LGBMRegressor()\n",
    "#param_LGBM = {'boosting_type': ['dart', 'gbdt'], 'num_leaves': [20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 300], 'verbose' : [-1] }\n",
    "\n",
    "#LGBM_cv = GridSearchCV(LGBM, param_LGBM,cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#LGBM_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out best score\n",
    "#np.sqrt(-1 * cat_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we're going to build out a Voting Regressor and feed our regressors into it for (hopefully) a better output\n",
    "\n",
    "voting_r = VotingRegressor([('GBR', GBR_cv.best_estimator_), ('XGB', GB_cv.best_estimator_), ('RFR', RF_cv.best_estimator_)], weights=[1,2,3])\n",
    "voting_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_vr = voting_r.predict(X_test)\n",
    "mean_squared_error(y_test, y_prediction_vr, squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an estimator regressor\n",
    "\n",
    "stimmies = [('gbr', GBR_cv.best_estimator_), ('xgb', GB_cv.best_estimator_), ('rfr', RF_cv.best_estimator_)]\n",
    "stacks = StackingRegressor(estimators=stimmies, final_estimator=voting_r)\n",
    "\n",
    "stacks.fit(X_train, y_train)\n",
    "y_prediction_stacks = stacks.predict(X_test)\n",
    "\n",
    "# MSE of our Stack regressor\n",
    "mean_squared_error(y_test, y_prediction_stacks, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now We will run the test data through our stack regressor model\n",
    "\n",
    "# Preprocessing our test data\n",
    "test_dataframe_pre = preprocess_pipeline.transform(test_dataframe)\n",
    "\n",
    "# Starting prediction and submitting data\n",
    "y_stack = np.exp(stacks.predict(test_dataframe_pre))\n",
    "y_dataframe_out = test_dataframe[['Id']]\n",
    "y_dataframe_out['SalePrice'] = y_stack\n",
    "y_dataframe_out.to_csv('results.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
